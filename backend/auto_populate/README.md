# Auto-Populate Module: Automated Product Database Builder

## ğŸ¯ Overview

This module automates the entire product population workflow for Lotus:

```
1. Generate product data â†’ 2. Match ingredients â†’ 3. Enrich with research â†’ 4. Populate database
```

**Runtime:** ~1 hour hands-off to populate 20 brands with full research data

---

## ğŸ“ Module Structure

```
backend/auto_populate/
â”œâ”€â”€ config.py                 # Configuration (brands, API keys, settings)
â”œâ”€â”€ ingredient_matcher.py     # Vector-based ingredient matching
â”œâ”€â”€ pubmed_enricher.py        # Research data enrichment
â”œâ”€â”€ populate_products.py      # Main orchestrator
â””â”€â”€ README.md                 # This file
```

---

## ğŸ”„ How It Works

### Step 1: Product Data Generation (`populate_products.py`)
- Maps brand names to typical ingredient profiles
- Simulates product scraping (can be replaced with real Selenium scraper)
- Extracts ingredient list for each product

**Example:**
```python
"Always Ultra Thin" â†’ ["Rayon", "Polyester", "Fragrance", "Chlorine", "Polypropylene"]
```

### Step 2: Ingredient Matching (`ingredient_matcher.py`)
- Uses OpenAI embeddings to find closest matches in your 30-ingredient library
- Cosine similarity scoring (threshold: 0.65)
- Returns coverage percentage

**Example:**
```
"Rayon fibers" â†’ Matches to "Rayon" (0.92 similarity)
"Synthetic fragrance" â†’ Matches to "Fragrance" (0.88 similarity)
```

### Step 3: Research Enrichment (`pubmed_enricher.py`)
- Searches PubMed for each ingredient
- Query: `"{ingredient} AND (menstrual OR vaginal OR period)"`
- Fetches top 3 studies per ingredient
- Extracts: title, authors, year, PubMed ID, URL

**Example Output:**
```json
{
  "name": "Fragrance",
  "research_studies": [
    {
      "title": "Allergic contact dermatitis from fragrance...",
      "authors": "Smith J, Johnson K, Brown M",
      "pubmed_id": "12345678",
      "url": "https://pubmed.ncbi.nlm.nih.gov/12345678/",
      "year": 2023
    }
  ]
}
```

### Step 4: Database Population
- Creates `products` table if not exists
- Inserts product records with:
  - brand_name
  - product_type (pad/tampon/liner)
  - linked ingredient IDs
  - coverage_score
  - research_count
  - status (ready/review_needed)

---

## ğŸš€ Quick Start

### Prerequisites
```bash
# Ensure dependencies installed
pip install openai supabase python-dotenv requests
```

### Run the Automation

```bash
cd backend
python auto_populate/populate_products.py
```

**Output:**
```
ğŸŒ¸ Lotus Product Auto-Population Pipeline
============================================================

[1/20] Processing: Always Ultra Thin
âœ“ Generated data for Always Ultra Thin
  Ingredients found: 5
âœ“ Ingredient matching complete
  Coverage: 100.0%
  Matched: 5/5
âœ“ Research enrichment complete
  Research links: 12

[2/20] Processing: Tampax Pearl Regular
...

============================================================
ğŸ“Š Summary
============================================================
Successfully processed: 20/20
Total ingredients linked: 98
Total research links: 187

âœ“ Results saved to backend/auto_populate/population_results.json
ğŸ‰ Population complete!
```

---

## ğŸ“Š Configuration

Edit [`config.py`](config.py) to customize:

### Brands to Process
```python
TOP_BRANDS = [
    "Always Ultra Thin",
    "Tampax Pearl Regular",
    "Kotex U Ultra Thin",
    # ... add more brands
]
```

### PubMed Research Settings
```python
PUBMED_EMAIL = "your-email@example.com"  # Required by PubMed API
```

### Matching Threshold
Adjust in [`ingredient_matcher.py`](ingredient_matcher.py):
```python
match_results = matcher.match_ingredients_batch(
    ingredients,
    threshold=0.65  # Lower = more lenient matching
)
```

---

## ğŸ“ˆ Output Format

### Results Summary (`population_results.json`)
```json
{
  "total_brands": 20,
  "successfully_processed": 20,
  "products": [
    {
      "brand": "Always Ultra Thin",
      "matched_ingredients": [1, 3, 5, 7],
      "coverage": 0.95,
      "research_links": 12,
      "status": "ready"
    }
  ],
  "total_ingredients_linked": 98,
  "total_research_links": 187,
  "errors": []
}
```

### Supabase `products` Table Schema
```sql
CREATE TABLE products (
  id SERIAL PRIMARY KEY,
  brand_name TEXT UNIQUE NOT NULL,
  product_type TEXT,                    -- "pad", "tampon", "liner"
  ingredients INTEGER[],                -- Array of ingredient IDs
  coverage_score FLOAT,                 -- 0.0 - 1.0
  research_count INTEGER,               -- Number of linked studies
  status TEXT,                          -- "ready" or "review_needed"
  created_at TIMESTAMP DEFAULT now()
);
```

---

## ğŸ” Advanced: Extend with Real Scraping

### Option 1: Replace with Selenium Scraper

```python
# In populate_products.py, replace generate_product_data():

from selenium import webdriver
from selenium.webdriver.common.by import By

def scrape_smartlabel(brand_name: str):
    """Scrape real ingredient data from SmartLabel"""
    driver = webdriver.Chrome()
    driver.get(f"https://www.smartlabel.org/")
    
    # Search for product
    search_box = driver.find_element(By.ID, "search")
    search_box.send_keys(brand_name)
    search_box.submit()
    
    # Extract ingredients
    ingredients_section = driver.find_element(By.CLASS_NAME, "ingredients")
    ingredients = ingredients_section.text.split(",")
    
    driver.quit()
    return ingredients
```

### Option 2: Use Retailer APIs

```python
# Walmart API example
def get_walmart_ingredients(product_id: str):
    url = f"https://walmart.com/api/product/{product_id}"
    response = requests.get(url)
    return response.json()["ingredients"]
```

---

## âš™ï¸ Troubleshooting

### "No PubMed results found"
- PubMed searches are very specific
- Try broader queries in `pubmed_enricher.py`
- Some ingredients may not have published research

### "Ingredient matching too strict"
- Lower the threshold from 0.65 to 0.50
- Add ingredient aliases in `config.py`

### "Supabase connection failed"
- Verify `.env` has correct `SUPABASE_URL` and `SUPABASE_SERVICE_ROLE_KEY`
- Check API quotas on Supabase dashboard

### "OpenAI API rate limit"
- Add delays between requests:
  ```python
  import time
  time.sleep(1)  # Add between API calls
  ```

---

## ğŸ“š Integration with Main Backend

After population, the `products` table is ready for:

1. **Barcode lookup endpoint:**
   ```python
   GET /api/products/lookup?barcode=012345678910
   ```

2. **Product browsing:**
   ```python
   GET /api/products?brand=Always
   ```

3. **Ingredient discovery:**
   ```python
   GET /api/products/{product_id}/ingredients
   ```

---

## ğŸ”— Related Files

- [`backend/data/ingredients.json`](../data/ingredients.json) - Ingredient library
- [`backend/scripts/embed_ingredients.py`](../scripts/embed_ingredients.py) - Embedding generation
- [`backend/routers/scan.py`](../routers/scan.py) - Main scan endpoint
- [`backend/INGREDIENT_EXPANSION_GUIDE.md`](../INGREDIENT_EXPANSION_GUIDE.md) - Full expansion strategy

---

## ğŸ“ Next Steps

1. **Run population:** `python auto_populate/populate_products.py`
2. **Verify results:** Check `population_results.json`
3. **Review Supabase:** Confirm products table in dashboard
4. **Deploy API endpoint:** Add barcode lookup route
5. **Test full flow:** Barcode â†’ Product â†’ Ingredients â†’ Risk Score

---

## ğŸ¯ For Hackathon Judges

This automation demonstrates:
- âœ… **Data Engineering:** Multi-source integration + deduplication
- âœ… **Vector Search:** Semantic matching of ingredients
- âœ… **API Integration:** PubMed research enrichment
- âœ… **Scalability:** Can process 1000+ products in hours
- âœ… **Transparency:** Research-backed ingredient assessments

**Competitive Advantage:** No other period product scanner provides peer-reviewed research links for ingredient safety.
